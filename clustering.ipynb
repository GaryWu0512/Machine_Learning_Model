{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# always import\n",
    "import sys\n",
    "from time import time\n",
    "\n",
    "# numpy & scipy\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "# sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.manifold import Isomap, TSNE\n",
    "from sklearn.metrics import pairwise_distances_argmin, pairwise_distances\n",
    "\n",
    "# visuals\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import offsetbox\n",
    "\n",
    "# maybe\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MNIST data and normalization\n",
    "from sklearn.datasets import fetch_openml\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, data_home='mnist/')\n",
    "y = np.asarray(list(map(int, y)))\n",
    "X = np.asarray(X.astype(float))\n",
    "X = scale(X)\n",
    "n_digits = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: kmeans with PCA initialization of centers, or random initial centers\n",
    "def kmeans_11(X, n_clusters, init=\"pca\", tol = 1.0e-4, max_iter = 300, n_init=10, rseed=2):\n",
    "    # 1. Randomly choose clusters\n",
    "    if init == \"pca\":\n",
    "        pca = PCA(n_components=n_clusters).fit(X)\n",
    "        centers = pca.fit(X).components_\n",
    "        n_init = 1\n",
    "        #print('centers:', centers.shape)\n",
    "    \n",
    "    best_obj = 0.0\n",
    "    for trial in range(n_init):\n",
    "        \n",
    "        if init == \"rand\":\n",
    "            rng = np.random.RandomState(rseed+trial)\n",
    "            i = rng.permutation(X.shape[0])[:n_clusters]\n",
    "            centers = X[i]\n",
    "        \n",
    "        iter = 0\n",
    "        obj = np.inf\n",
    "        while iter < max_iter:\n",
    "            # 2a. Assign labels based on closest center\n",
    "            labels = pairwise_distances_argmin(X, centers)\n",
    "            #print('labels:', np.unique(labels))\n",
    "\n",
    "            # 2b. Find new centers from means of points\n",
    "            new_centers = np.array([X[labels == i].mean(0)\n",
    "                                    for i in range(n_clusters)])\n",
    "\n",
    "            # 2c. Check for convergence\n",
    "            new_obj = X - new_centers[labels]\n",
    "            new_obj = np.sum(new_obj * new_obj)\n",
    "            if obj - new_obj < tol:\n",
    "                break\n",
    "            else:\n",
    "                centers = new_centers\n",
    "                obj = new_obj\n",
    "\n",
    "            iter += 1\n",
    "            \n",
    "        if trial == 0 or obj < best_obj:\n",
    "            best_obj = obj\n",
    "            best_centers = centers\n",
    "            best_labels = labels               \n",
    "    \n",
    "    return best_centers, best_labels, best_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "pca = PCA(n_components=30).fit(X)\n",
    "X_pca = pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans   \t135.78s\t42569895\t0.420\t0.442\t0.431\t0.320\t0.420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tianyizhou/anaconda3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:732: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# kmeans with PCA pre-processing\n",
    "t0 = time()\n",
    "# pca = PCA(n_components=50).fit(X)\n",
    "# X_pca = pca.transform(X)\n",
    "# kmeans_pca = KMeans(init='k-means++', n_clusters=n_digits, n_init=10)\n",
    "# kmeans_pca.fit(X_pca)\n",
    "best_centers, best_labels1, best_obj = kmeans_11(X, n_clusters=n_digits, init=\"pca\", rseed=2)\n",
    "# print('%-9s\\t%.2fs\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f'\n",
    "#       % (\"kmeans\", (time() - t0), kmeans.inertia_,\n",
    "#          metrics.homogeneity_score(y, kmeans.labels_),\n",
    "#          metrics.completeness_score(y, kmeans.labels_),\n",
    "#          metrics.v_measure_score(y, kmeans.labels_),\n",
    "#          metrics.adjusted_rand_score(y, kmeans.labels_),\n",
    "#          metrics.adjusted_mutual_info_score(y,  kmeans.labels_)))\n",
    "print('%-9s\\t%.2fs\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f'\n",
    "      % (\"kmeans\", (time() - t0), best_obj,\n",
    "         metrics.homogeneity_score(y, best_labels1),\n",
    "         metrics.completeness_score(y, best_labels1),\n",
    "         metrics.v_measure_score(y, best_labels1),\n",
    "         metrics.adjusted_rand_score(y, best_labels1),\n",
    "         metrics.adjusted_mutual_info_score(y, best_labels1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans   \t42.05s\t15013070\t0.423\t0.444\t0.433\t0.323\t0.423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tianyizhou/anaconda3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:732: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# kmeans with 10 random trials\n",
    "t0 = time()\n",
    "# kmeans_pca = KMeans(init='k-means++', n_clusters=n_digits, n_init=10)\n",
    "# kmeans_pca.fit(X_pca)\n",
    "best_centers, best_labels2, best_obj = kmeans_11(X_pca, n_clusters=n_digits, init=\"rand\", rseed=2, n_init=10)\n",
    "# print('%-9s\\t%.2fs\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f'\n",
    "#       % (\"kmeans\", (time() - t0), kmeans_pca.inertia_,\n",
    "#          metrics.homogeneity_score(y, kmeans_pca.labels_),\n",
    "#          metrics.completeness_score(y, kmeans_pca.labels_),\n",
    "#          metrics.v_measure_score(y, kmeans_pca.labels_),\n",
    "#          metrics.adjusted_rand_score(y, kmeans_pca.labels_),\n",
    "#          metrics.adjusted_mutual_info_score(y,  kmeans_pca.labels_)))\n",
    "print('%-9s\\t%.2fs\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f'\n",
    "      % (\"kmeans\", (time() - t0), best_obj,\n",
    "         metrics.homogeneity_score(y, best_labels2),\n",
    "         metrics.completeness_score(y, best_labels2),\n",
    "         metrics.v_measure_score(y, best_labels2),\n",
    "         metrics.adjusted_rand_score(y, best_labels2),\n",
    "         metrics.adjusted_mutual_info_score(y, best_labels2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Hungarian algorithm\n",
    "class _Hungary(object):\n",
    "    \"\"\"State of the Hungarian algorithm.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cost_matrix : 2D matrix\n",
    "        The cost matrix. Must have shape[1] >= shape[0].\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cost_matrix):\n",
    "        self.C = cost_matrix.copy()\n",
    "\n",
    "        n, m = self.C.shape\n",
    "        self.row_uncovered = np.ones(n, dtype=bool)\n",
    "        self.col_uncovered = np.ones(m, dtype=bool)\n",
    "        self.Z0_r = 0\n",
    "        self.Z0_c = 0\n",
    "        self.path = np.zeros((n + m, 2), dtype=int)\n",
    "        self.marked = np.zeros((n, m), dtype=int)\n",
    "\n",
    "    def _clear_covers(self):\n",
    "        \"\"\"Clear all covered matrix cells\"\"\"\n",
    "        self.row_uncovered[:] = True\n",
    "        self.col_uncovered[:] = True\n",
    "\n",
    "\n",
    "# Individual steps of the algorithm follow, as a state machine: they return\n",
    "# the next step to be taken (function to be called), if any.\n",
    "\n",
    "def _step1(state):\n",
    "    \"\"\"Steps 1 and 2 in the Wikipedia page.\"\"\"\n",
    "\n",
    "    # Step 1: For each row of the matrix, find the smallest element and\n",
    "    # subtract it from every element in its row.\n",
    "    state.C -= state.C.min(axis=1)[:, np.newaxis]\n",
    "    # Step 2: Find a zero (Z) in the resulting matrix. If there is no\n",
    "    # starred zero in its row or column, star Z. Repeat for each element\n",
    "    # in the matrix.\n",
    "    for i, j in zip(*np.where(state.C == 0)):\n",
    "        if state.col_uncovered[j] and state.row_uncovered[i]:\n",
    "            state.marked[i, j] = 1\n",
    "            state.col_uncovered[j] = False\n",
    "            state.row_uncovered[i] = False\n",
    "\n",
    "    state._clear_covers()\n",
    "    return _step3\n",
    "\n",
    "\n",
    "def _step3(state):\n",
    "    \"\"\"\n",
    "    Cover each column containing a starred zero. If n columns are covered,\n",
    "    the starred zeros describe a complete set of unique assignments.\n",
    "    In this case, Go to DONE, otherwise, Go to Step 4.\n",
    "    \"\"\"\n",
    "    marked = (state.marked == 1)\n",
    "    state.col_uncovered[np.any(marked, axis=0)] = False\n",
    "\n",
    "    if marked.sum() < state.C.shape[0]:\n",
    "        return _step4\n",
    "\n",
    "\n",
    "def _step4(state):\n",
    "    \"\"\"\n",
    "    Find a noncovered zero and prime it. If there is no starred zero\n",
    "    in the row containing this primed zero, Go to Step 5. Otherwise,\n",
    "    cover this row and uncover the column containing the starred\n",
    "    zero. Continue in this manner until there are no uncovered zeros\n",
    "    left. Save the smallest uncovered value and Go to Step 6.\n",
    "    \"\"\"\n",
    "    # We convert to int as numpy operations are faster on int\n",
    "    C = (state.C == 0).astype(int)\n",
    "    covered_C = C * state.row_uncovered[:, np.newaxis]\n",
    "    covered_C *= np.asarray(state.col_uncovered, dtype=int)\n",
    "    n = state.C.shape[0]\n",
    "    m = state.C.shape[1]\n",
    "\n",
    "    while True:\n",
    "        # Find an uncovered zero\n",
    "        row, col = np.unravel_index(np.argmax(covered_C), (n, m))\n",
    "        if covered_C[row, col] == 0:\n",
    "            return _step6\n",
    "        else:\n",
    "            state.marked[row, col] = 2\n",
    "            # Find the first starred element in the row\n",
    "            star_col = np.argmax(state.marked[row] == 1)\n",
    "            if state.marked[row, star_col] != 1:\n",
    "                # Could not find one\n",
    "                state.Z0_r = row\n",
    "                state.Z0_c = col\n",
    "                return _step5\n",
    "            else:\n",
    "                col = star_col\n",
    "                state.row_uncovered[row] = False\n",
    "                state.col_uncovered[col] = True\n",
    "                covered_C[:, col] = C[:, col] * (\n",
    "                    np.asarray(state.row_uncovered, dtype=int))\n",
    "                covered_C[row] = 0\n",
    "\n",
    "\n",
    "def _step5(state):\n",
    "    \"\"\"\n",
    "    Construct a series of alternating primed and starred zeros as follows.\n",
    "    Let Z0 represent the uncovered primed zero found in Step 4.\n",
    "    Let Z1 denote the starred zero in the column of Z0 (if any).\n",
    "    Let Z2 denote the primed zero in the row of Z1 (there will always be one).\n",
    "    Continue until the series terminates at a primed zero that has no starred\n",
    "    zero in its column. Unstar each starred zero of the series, star each\n",
    "    primed zero of the series, erase all primes and uncover every line in the\n",
    "    matrix. Return to Step 3\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    path = state.path\n",
    "    path[count, 0] = state.Z0_r\n",
    "    path[count, 1] = state.Z0_c\n",
    "\n",
    "    while True:\n",
    "        # Find the first starred element in the col defined by\n",
    "        # the path.\n",
    "        row = np.argmax(state.marked[:, path[count, 1]] == 1)\n",
    "        if state.marked[row, path[count, 1]] != 1:\n",
    "            # Could not find one\n",
    "            break\n",
    "        else:\n",
    "            count += 1\n",
    "            path[count, 0] = row\n",
    "            path[count, 1] = path[count - 1, 1]\n",
    "\n",
    "        # Find the first prime element in the row defined by the\n",
    "        # first path step\n",
    "        col = np.argmax(state.marked[path[count, 0]] == 2)\n",
    "        if state.marked[row, col] != 2:\n",
    "            col = -1\n",
    "        count += 1\n",
    "        path[count, 0] = path[count - 1, 0]\n",
    "        path[count, 1] = col\n",
    "\n",
    "    # Convert paths\n",
    "    for i in range(count + 1):\n",
    "        if state.marked[path[i, 0], path[i, 1]] == 1:\n",
    "            state.marked[path[i, 0], path[i, 1]] = 0\n",
    "        else:\n",
    "            state.marked[path[i, 0], path[i, 1]] = 1\n",
    "\n",
    "    state._clear_covers()\n",
    "    # Erase all prime markings\n",
    "    state.marked[state.marked == 2] = 0\n",
    "    return _step3\n",
    "\n",
    "\n",
    "def _step6(state):\n",
    "    \"\"\"\n",
    "    Add the value found in Step 4 to every element of each covered row,\n",
    "    and subtract it from every element of each uncovered column.\n",
    "    Return to Step 4 without altering any stars, primes, or covered lines.\n",
    "    \"\"\"\n",
    "    # the smallest uncovered value in the matrix\n",
    "    if np.any(state.row_uncovered) and np.any(state.col_uncovered):\n",
    "        minval = np.min(state.C[state.row_uncovered], axis=0)\n",
    "        minval = np.min(minval[state.col_uncovered])\n",
    "        state.C[~state.row_uncovered] += minval\n",
    "        state.C[:, state.col_uncovered] -= minval\n",
    "    return _step4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions when using Hungarian algorithm for clustering evaluation\n",
    "# from munkres import Munkres\n",
    "\n",
    "def make_cost_matrix(c1, c2):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    uc1 = np.unique(c1)\n",
    "    uc2 = np.unique(c2)\n",
    "    l1 = uc1.size\n",
    "    l2 = uc2.size\n",
    "    assert(l1 == l2 and np.all(uc1 == uc2))\n",
    "\n",
    "    m = np.ones([l1, l2])\n",
    "    for i in range(l1):\n",
    "        it_i = np.nonzero(c1 == uc1[i])[0]\n",
    "        for j in range(l2):\n",
    "            it_j = np.nonzero(c2 == uc2[j])[0]\n",
    "            m_ij = np.intersect1d(it_j, it_i)\n",
    "            m[i,j] =  -m_ij.size\n",
    "    return m\n",
    "\n",
    "def translate_clustering(clt, mapper):\n",
    "    return np.array([ mapper[i] for i in clt ])\n",
    "\n",
    "def accuracy(cm):\n",
    "    \"\"\"computes accuracy from confusion matrix\"\"\"\n",
    "    return np.trace(cm, dtype=float) / np.sum(cm)\n",
    "\n",
    "def Hungarian_caller(y_pred, y_true):\n",
    "    \n",
    "    cost_matrix = make_cost_matrix(y_pred, y_true)\n",
    "\n",
    "#     m = Munkres()\n",
    "#     indexes = m.compute(cost_matrix)\n",
    "    state = _Hungary(cost_matrix)\n",
    "    step = None if 0 in cost_matrix.shape else _step1\n",
    "    while step is not None:\n",
    "        step = step(state)\n",
    "    marked = state.marked\n",
    "    indexes = np.where(marked == 1)\n",
    "    \n",
    "    mapper = { old: new for (old, new) in zip(indexes[0], indexes[1])}\n",
    "\n",
    "    print(\"---------------------\\nmapping:\")\n",
    "    for old, new in mapper.items():\n",
    "        print(\"map: %s --> %s\" %(old, new))\n",
    "        \n",
    "    new_pred = translate_clustering(y_pred, mapper)\n",
    "    num_labels = len(np.unique(y_true))\n",
    "    new_cm = confusion_matrix(y_true, new_pred, labels=range(num_labels))\n",
    "    new_acc = accuracy(new_cm)\n",
    "    print(\"---------------------\\nnew confusion matrix:\\n\" \\\n",
    "              \" %s\\naccuracy: %.2f\" % (str(new_cm), new_acc))\n",
    "    \n",
    "    return new_pred, new_cm, new_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "mapping:\n",
      "map: 0 --> 0\n",
      "map: 1 --> 9\n",
      "map: 2 --> 2\n",
      "map: 3 --> 6\n",
      "map: 4 --> 1\n",
      "map: 5 --> 3\n",
      "map: 6 --> 8\n",
      "map: 7 --> 7\n",
      "map: 8 --> 5\n",
      "map: 9 --> 4\n",
      "---------------------\n",
      "new confusion matrix:\n",
      " [[3810   35  112 1425   12  503  341    6  649   10]\n",
      " [   0 7644   13   26    8  154   16    5   10    1]\n",
      " [  37  829 2388  717  189   67  846   32 1844   41]\n",
      " [   9  574  747 4089  204   97   83   97 1136  105]\n",
      " [  55  535   73    5 3967  936  127  753   30  343]\n",
      " [  31  464  247 2167  311 2662  101   88  179   63]\n",
      " [ 292  564  415  115   28  119 5322    1   15    5]\n",
      " [  20  516   16    9 1581  137    3 4082   13  916]\n",
      " [  44 1172  206 2635  358 2026   32  188   91   73]\n",
      " [  44  332   23  124 3485  124    5 2374   16  431]]\n",
      "accuracy: 0.49\n"
     ]
    }
   ],
   "source": [
    "new_pred, new_cm, new_acc = Hungarian_caller(best_labels1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "mapping:\n",
      "map: 0 --> 0\n",
      "map: 1 --> 6\n",
      "map: 2 --> 5\n",
      "map: 3 --> 1\n",
      "map: 4 --> 2\n",
      "map: 5 --> 4\n",
      "map: 6 --> 7\n",
      "map: 7 --> 3\n",
      "map: 8 --> 8\n",
      "map: 9 --> 9\n",
      "---------------------\n",
      "new confusion matrix:\n",
      " [[3990   32   82  934   20  663  764    7  398   13]\n",
      " [   0 7620   13   29    6  172   16    7   13    1]\n",
      " [  41  824 2570  790  159   91  696   44 1719   56]\n",
      " [  13  671  220 4449  185  149   97   92 1141  124]\n",
      " [  50  538   49    3 3948  900  161  673   24  478]\n",
      " [  36  528  128 2059  324 2806  129   66  156   81]\n",
      " [ 238  497  777   54   37  134 5123    1    9    6]\n",
      " [  20  549    7   14 1608  110    3 4054   18  910]\n",
      " [  49 1344   96 2227  402 2281   56  184   78  108]\n",
      " [  41  352   15  106 3522  118    7 2262   15  520]]\n",
      "accuracy: 0.50\n"
     ]
    }
   ],
   "source": [
    "new_pred, new_cm, new_acc = Hungarian_caller(best_labels2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn graph time = 116.75337314605713\n",
      "sigma= 10.826615024646268\n",
      "E_sum= 21540402.226940256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tianyizhou/anaconda3/lib/python3.6/site-packages/scipy/sparse/compressed.py:708: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self[i, j] = values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nonzeros= 35070000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import radius_neighbors_graph\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn import neighbors\n",
    "# subset = np.random.choice(len(X), 50000, replace=False)\n",
    "# knn_graph = radius_neighbors_graph(X_pca[subset], 10.0, mode='distance', metric='minkowski', p=2, metric_params=None, include_self=False)\n",
    "# A = kneighbors_graph(X[subset], 10, mode='distance', metric='minkowski', p=2, metric_params=None, include_self=False)\n",
    "nn = neighbors.NearestNeighbors(n_neighbors=500, algorithm='kd_tree', metric='euclidean', n_jobs=8)\n",
    "# nn = neighbors.NearestNeighbors(n_neighbors=500, metric='l1', n_jobs=8)\n",
    "t0 = time()\n",
    "knn_graph = nn.fit(X_pca).kneighbors_graph(mode='distance')\n",
    "print('knn graph time =', time()-t0)\n",
    "sigma = knn_graph.data.sum()/float(knn_graph.size)\n",
    "print('sigma=', sigma)\n",
    "knn_graph.data = np.exp(-1.0 * np.divide(np.power(knn_graph.data, 2), 2*sigma**2))\n",
    "print('E_sum=', knn_graph.data.sum())\n",
    "knn_graph.data /= knn_graph.data.sum()\n",
    "# knn_graph.data = 1.0 - knn_graph.data\n",
    "print('nonzeros=', knn_graph.count_nonzero())\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute Graph Laplacian (symmetric normalized in hw)\n",
    "def _setdiag_dense(A, d):\n",
    "    A.flat[::len(d)+1] = d\n",
    "\n",
    "def _laplacian_sparse(graph, normed=False, axis=0):\n",
    "    if graph.format in ('lil', 'dok'):\n",
    "        m = graph.tocoo()\n",
    "        needs_copy = False\n",
    "    else:\n",
    "        m = graph\n",
    "        needs_copy = True\n",
    "    w = m.sum(axis=axis).getA1() - m.diagonal()\n",
    "    if normed:\n",
    "        m = m.tocoo(copy=needs_copy)\n",
    "        isolated_node_mask = (w == 0)\n",
    "        w = np.where(isolated_node_mask, 1, np.sqrt(w))\n",
    "        m.data /= w[m.row]\n",
    "        m.data /= w[m.col]\n",
    "        m.data *= -1\n",
    "        m.setdiag(1 - isolated_node_mask)\n",
    "    else:\n",
    "        if m.format == 'dia':\n",
    "            m = m.copy()\n",
    "        else:\n",
    "            m = m.tocoo(copy=needs_copy)\n",
    "        m.data *= -1\n",
    "        m.setdiag(w)\n",
    "    return m, w\n",
    "\n",
    "def _laplacian_dense(graph, normed=False, axis=0):\n",
    "    m = np.array(graph)\n",
    "    np.fill_diagonal(m, 0)\n",
    "    w = m.sum(axis=axis)\n",
    "    if normed:\n",
    "        isolated_node_mask = (w == 0)\n",
    "        w = np.where(isolated_node_mask, 1, np.sqrt(w))\n",
    "        m /= w\n",
    "        m /= w[:, np.newaxis]\n",
    "        m *= -1\n",
    "        _setdiag_dense(m, 1 - isolated_node_mask)\n",
    "    else:\n",
    "        m *= -1\n",
    "        _setdiag_dense(m, w)\n",
    "    return m, w\n",
    "\n",
    "def laplacian(csgraph, normed):\n",
    "    create_lap = _laplacian_sparse if scipy.sparse.isspmatrix(csgraph) else _laplacian_dense\n",
    "    lap, d = create_lap(csgraph, normed=normed)\n",
    "    return lap, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Spectral Clustering\n",
    "def spectral_clustering(affinity, n_clusters):\n",
    "    L, d = laplacian((affinity + affinity.transpose())/2.0, normed=True)\n",
    "#     L, d = laplacian(affinity, normed=True)\n",
    "    t0 = time()\n",
    "    eig_val, eig_vect = scipy.sparse.linalg.eigs(L, min(n_clusters+10, 30), which='SM')\n",
    "    print('eigendecomp time =', time()-t0)\n",
    "    X = eig_vect[:, 1:].real\n",
    "    rows_norm = np.linalg.norm(X, axis=1, ord=2)\n",
    "    Y = (X.T / rows_norm).T\n",
    "    kmeans = KMeans(init='k-means++', n_clusters=n_clusters, n_init=20)\n",
    "    kmeans.fit(Y)\n",
    "#     best_centers, best_labels, best_obj = kmeans_11(Y, n_clusters=n_digits, init=\"pca\", rseed=2)\n",
    "#     return best_centers, best_labels, Y\n",
    "    return kmeans.cluster_centers_, kmeans.labels_, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigendecomp time = 39.77084422111511\n"
     ]
    }
   ],
   "source": [
    "sc_centers, sc_pred, _ = spectral_clustering(knn_graph, n_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.sparse.isspmatrix_csr(knn_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50060092"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(knn_graph + knn_graph.transpose()).count_nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "mapping:\n",
      "map: 0 --> 2\n",
      "map: 1 --> 9\n",
      "map: 2 --> 3\n",
      "map: 3 --> 4\n",
      "map: 4 --> 8\n",
      "map: 5 --> 6\n",
      "map: 6 --> 0\n",
      "map: 7 --> 1\n",
      "map: 8 --> 7\n",
      "map: 9 --> 5\n",
      "---------------------\n",
      "new confusion matrix:\n",
      " [[6643    4   17   36   11   79   58    4   49    2]\n",
      " [   0 7750   31   23   16   18   22    3   12    2]\n",
      " [  86   79 5437  222   17  828   38   60  187   36]\n",
      " [  16   98   91 4760   33 1647   14  111  311   60]\n",
      " [  15   90   76   16 3981  109   39   24    9 2465]\n",
      " [ 104   40   27 1838  101 3625  143   15  284  136]\n",
      " [ 262   75   99   31    7   91 6282    1   21    7]\n",
      " [  21  214   39   23  294   55    0 6175    8  464]\n",
      " [  76  102   51 1035   86  620   24   28 4680  123]\n",
      " [  39   62   24  100 3600   34    1  586   41 2471]]\n",
      "accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "new_pred, new_cm, new_acc = Hungarian_caller(sc_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: KNN defined on data selection by kmeans\n",
    "def find_landmark(X, centers):\n",
    "    index = pairwise_distances_argmin(centers, X)\n",
    "    return index\n",
    "\n",
    "def knn(X, landmarks, y, k):\n",
    "    dis = pairwise_distances(X, landmarks)\n",
    "    vote = dis.argpartition(k, axis=1)[:, :k]\n",
    "    for i in range(k):\n",
    "        vote[:, i] = y[vote[:, i]]\n",
    "    labels = list(map(lambda v: max(set(v), key = list(v).count), vote))\n",
    "    return labels\n",
    "\n",
    "def eval_knn_kmeans(X, y, k, centers):\n",
    "    train_index = find_landmark(X, centers)\n",
    "    test_index = np.setdiff1d(np.arange(len(X)), train_index, assume_unique=True)\n",
    "    test_pred = knn(X[test_index], X[train_index], y[train_index], k)\n",
    "    acc = np.sum(test_pred == y[test_index])/float(len(test_index))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=100, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: kmeans based KNN: find a sample closest to each kmeans centroid, and use them as training set for KNN (K=1)\n",
    "# best_centers, best_labels, best_obj = kmeans_11(X, n_clusters=n_digits*5, init=\"pca\", rseed=2)\n",
    "kmeans_pca = KMeans(init='k-means++', n_clusters=n_digits*10, n_init=10)\n",
    "kmeans_pca.fit(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans centroids based KNN (K=1) accuracy: 0.8140629470672389\n",
      "kmeans centroids based KNN (K=3) accuracy: 0.7717310443490701\n",
      "kmeans centroids based KNN (K=5) accuracy: 0.7438483547925608\n"
     ]
    }
   ],
   "source": [
    "acc = eval_knn_kmeans(X_pca, y, 1, kmeans_pca.cluster_centers_)\n",
    "print('kmeans centroids based KNN (K=1) accuracy:', acc)\n",
    "acc = eval_knn_kmeans(X_pca, y, 3, kmeans_pca.cluster_centers_)\n",
    "print('kmeans centroids based KNN (K=3) accuracy:', acc)\n",
    "acc = eval_knn_kmeans(X_pca, y, 5, kmeans_pca.cluster_centers_)\n",
    "print('kmeans centroids based KNN (K=5) accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=200, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_pca = KMeans(init='k-means++', n_clusters=n_digits*20, n_init=10)\n",
    "kmeans_pca.fit(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans centroids based KNN (K=1) accuracy: 0.8614756446991404\n",
      "kmeans centroids based KNN (K=3) accuracy: 0.8358022922636104\n",
      "kmeans centroids based KNN (K=5) accuracy: 0.8216905444126075\n"
     ]
    }
   ],
   "source": [
    "acc = eval_knn_kmeans(X_pca, y, 1, kmeans_pca.cluster_centers_)\n",
    "print('kmeans centroids based KNN (K=1) accuracy:', acc)\n",
    "acc = eval_knn_kmeans(X_pca, y, 3, kmeans_pca.cluster_centers_)\n",
    "print('kmeans centroids based KNN (K=3) accuracy:', acc)\n",
    "acc = eval_knn_kmeans(X_pca, y, 5, kmeans_pca.cluster_centers_)\n",
    "print('kmeans centroids based KNN (K=5) accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random samples based KNN (K=1) accuracy: 0.680829756795422\n",
      "random samples based KNN (K=3) accuracy: 0.6800143061516452\n",
      "random samples based KNN (K=5) accuracy: 0.595450643776824\n",
      "random samples based KNN (K=1) accuracy: 0.7710888252148997\n",
      "random samples based KNN (K=3) accuracy: 0.7227363896848138\n",
      "random samples based KNN (K=5) accuracy: 0.7543696275071633\n"
     ]
    }
   ],
   "source": [
    "# TODO: random sampling n_digits*10 samples, and use them as training set for KNN (K=1)\n",
    "acc = eval_knn_kmeans(X_pca, y, 1, X_pca[np.random.choice(len(X_pca), n_digits*10, replace=False)])\n",
    "print('random samples based KNN (K=1) accuracy:', acc)\n",
    "acc = eval_knn_kmeans(X_pca, y, 3, X_pca[np.random.choice(len(X_pca), n_digits*10, replace=False)])\n",
    "print('random samples based KNN (K=3) accuracy:', acc)\n",
    "acc = eval_knn_kmeans(X_pca, y, 5, X_pca[np.random.choice(len(X_pca), n_digits*10, replace=False)])\n",
    "print('random samples based KNN (K=5) accuracy:', acc)\n",
    "\n",
    "acc = eval_knn_kmeans(X_pca, y, 1, X_pca[np.random.choice(len(X_pca), n_digits*20, replace=False)])\n",
    "print('random samples based KNN (K=1) accuracy:', acc)\n",
    "acc = eval_knn_kmeans(X_pca, y, 3, X_pca[np.random.choice(len(X_pca), n_digits*20, replace=False)])\n",
    "print('random samples based KNN (K=3) accuracy:', acc)\n",
    "acc = eval_knn_kmeans(X_pca, y, 5, X_pca[np.random.choice(len(X_pca), n_digits*20, replace=False)])\n",
    "print('random samples based KNN (K=5) accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigendecomp time = 39.07061696052551\n"
     ]
    }
   ],
   "source": [
    "# TODO: test spectral clustering based KNN\n",
    "sc_centers, sc_pred, X_lap = spectral_clustering(knn_graph, n_digits*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectral clustering based KNN (K=1) accuracy: 0.8470243204577969\n",
      "spectral clustering based KNN (K=3) accuracy: 0.833447782546495\n",
      "spectral clustering based KNN (K=5) accuracy: 0.817997138769671\n"
     ]
    }
   ],
   "source": [
    "sc_acc = eval_knn_kmeans(X_lap, y, 1, sc_centers)\n",
    "print('spectral clustering based KNN (K=1) accuracy:', sc_acc)\n",
    "sc_acc = eval_knn_kmeans(X_lap, y, 3, sc_centers)\n",
    "print('spectral clustering based KNN (K=3) accuracy:', sc_acc)\n",
    "sc_acc = eval_knn_kmeans(X_lap, y, 5, sc_centers)\n",
    "print('spectral clustering based KNN (K=5) accuracy:', sc_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigendecomp time = 39.43999218940735\n"
     ]
    }
   ],
   "source": [
    "# TODO: test spectral clustering based KNN\n",
    "sc_centers, sc_pred, X_lap = spectral_clustering(knn_graph, n_digits*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectral clustering based KNN (K=1) accuracy: 0.8296131805157593\n",
      "spectral clustering based KNN (K=3) accuracy: 0.8303151862464183\n",
      "spectral clustering based KNN (K=5) accuracy: 0.8231375358166189\n"
     ]
    }
   ],
   "source": [
    "sc_acc = eval_knn_kmeans(X_lap, y, 1, sc_centers)\n",
    "print('spectral clustering based KNN (K=1) accuracy:', sc_acc)\n",
    "sc_acc = eval_knn_kmeans(X_lap, y, 3, sc_centers)\n",
    "print('spectral clustering based KNN (K=3) accuracy:', sc_acc)\n",
    "sc_acc = eval_knn_kmeans(X_lap, y, 5, sc_centers)\n",
    "print('spectral clustering based KNN (K=5) accuracy:', sc_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale and visualize the embedding vectors\n",
    "def plot_embedding(X, title=None):\n",
    "    x_min, x_max = np.min(X, 0), np.max(X, 0)\n",
    "    X = (X - x_min) / (x_max - x_min)\n",
    "\n",
    "    plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "    for i in range(X.shape[0]):\n",
    "        plt.text(X[i, 0], X[i, 1], str(y[i]),\n",
    "                 color=plt.cm.Set1(y[i] / 10.),\n",
    "                 fontdict={'weight': 'bold', 'size': 9})\n",
    "\n",
    "    if hasattr(offsetbox, 'AnnotationBbox'):\n",
    "        # only print thumbnails with matplotlib > 1.0\n",
    "        shown_images = np.array([[1., 1.]])  # just something big\n",
    "        for i in range(X.shape[0]):\n",
    "            dist = np.sum((X[i] - shown_images) ** 2, 1)\n",
    "            if np.min(dist) < 4e-3:\n",
    "                # don't show points that are too close\n",
    "                continue\n",
    "            shown_images = np.r_[shown_images, [X[i]]]\n",
    "            imagebox = offsetbox.AnnotationBbox(\n",
    "                offsetbox.OffsetImage(digits.images[i], cmap=plt.cm.gray_r),\n",
    "                X[i])\n",
    "            ax.add_artist(imagebox)\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    if title is not None:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE embedding of the digits dataset\n",
    "print(\"Computing t-SNE embedding\")\n",
    "tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "t0 = time()\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "plot_embedding(X_tsne,\n",
    "               \"t-SNE embedding of the digits (time %.2fs)\" %\n",
    "               (time() - t0))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isomap projection of the digits dataset\n",
    "print(\"Computing Isomap embedding\")\n",
    "t0 = time()\n",
    "X_iso = manifold.Isomap(n_neighbors, n_components=2).fit_transform(X)\n",
    "print(\"Done.\")\n",
    "plot_embedding(X_iso,\n",
    "               \"Isomap projection of the digits (time %.2fs)\" %\n",
    "               (time() - t0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
